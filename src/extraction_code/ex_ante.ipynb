{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41828c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extraction import extract_articles_from_google\n",
    "from extraction import extract_data_from_page\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72be2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_file_name = \"ex_ante_articles.json\"\n",
    "content_file_name = \"ex_ante_articles_with_content.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_articles_from_google(\n",
    "\twebsite=\"ex-ante.cl\",\n",
    "\tnewscast=\"Ex-Ante\",\n",
    "    pages=2,\n",
    "    output=pages_file_name,\n",
    "    keywords=\"Estallido Social\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c592c881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Input file: ex_ante_articles.json\n",
      "[INFO] Output file: ex_ante_articles_with_content.json\n",
      "[INFO] Limit of pages to process: 5\n",
      "\n",
      "[INFO] Loading extracted pages from JSON file...\n",
      "[INFO] Starting extraction process...\n",
      "\n",
      "[INFO] Checking page: 0 | Link: https://www.ex-ante.cl/cronica-de-una-escualida-y-violenta-protesta-en-plaza-baquedano-a-cuatro-anos-del-estallido/\n",
      "[INFO] Storing information in a JSON file...\n",
      "\n",
      "[INFO] Checking page: 1 | Link: https://www.ex-ante.cl/estallido-social-la-necesidad-de-separar-causas-y-consecuencias-por-cristian-valdivieso/\n",
      "[ERROR] An error occurred while processing page 1: Message: session not created: cannot connect to chrome at 127.0.0.1:57773\n",
      "from chrome not reachable; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#sessionnotcreatedexception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x125d2a3+66419]\n",
      "\tGetHandleVerifier [0x0x125d2e4+66484]\n",
      "\t(No symbol) [0x0x1034a20]\n",
      "\t(No symbol) [0x0x102866b]\n",
      "\t(No symbol) [0x0x106edcf]\n",
      "\t(No symbol) [0x0x1064e6f]\n",
      "\t(No symbol) [0x0x1064c96]\n",
      "\t(No symbol) [0x0x10acce4]\n",
      "\t(No symbol) [0x0x10ac5ea]\n",
      "\t(No symbol) [0x0x10a0e16]\n",
      "\t(No symbol) [0x0x10725ce]\n",
      "\t(No symbol) [0x0x10734a4]\n",
      "\tGetHandleVerifier [0x0x14a5ee3+2461619]\n",
      "\tGetHandleVerifier [0x0x14a0f66+2441270]\n",
      "\tGetHandleVerifier [0x0x1286242+234258]\n",
      "\tGetHandleVerifier [0x0x1276208+168664]\n",
      "\tGetHandleVerifier [0x0x127d1ad+197245]\n",
      "\tGetHandleVerifier [0x0x12655f8+100040]\n",
      "\tGetHandleVerifier [0x0x1265792+100450]\n",
      "\tGetHandleVerifier [0x0x124f74a+10266]\n",
      "\tBaseThreadInitThunk [0x0x7690fcc9+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x779982ae+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x7799827e+238]\n",
      "\n",
      "[INFO] Storing information in a JSON file...\n",
      "\n",
      "[INFO] Checking page: 2 | Link: https://www.ex-ante.cl/especial-18-o-capitulo-6-las-primeras-48-horas-del-estallido-social-vistas-desde-la-moneda/\n",
      "[INFO] Storing information in a JSON file...\n",
      "\n",
      "[INFO] Checking page: 3 | Link: https://www.ex-ante.cl/https-www-ex-ante-cl-la-noche-mas-tensa-de-la-crisis-de-octubre-el-dialogo-de-pinera-con-el-jefe-del-ejercito/\n",
      "[INFO] Storing information in a JSON file...\n",
      "\n",
      "[INFO] Checking page: 4 | Link: https://www.ex-ante.cl/alfredo-joignant-estamos-viviendo-la-extincion-del-hechizo-del-estallido-social/\n",
      "[INFO] Storing information in a JSON file...\n",
      "[INFO] Limit of pages reached.\n"
     ]
    }
   ],
   "source": [
    "def get_content(body: WebElement):\n",
    "\twords_to_avoid = [\n",
    "\t\t\"También puede leer.\",\n",
    "\t\t\"Lea también\",\n",
    "\t\t\"Para seguir leyendo columnas de Ex-Ante, clic aquí.\",\n",
    "\t\t\"(Lea aquí la encuesta completa)\"\n",
    "\t]\n",
    "\tcontent = \"\"\n",
    "\tfor element in body.find_element(By.CLASS_NAME, \"contenido-noticia\").find_elements(By.TAG_NAME, \"p\"):\n",
    "\t\tif any(phrase in element.text for phrase in words_to_avoid):\n",
    "\t\t\tcontinue\n",
    "\t\tcontent += element.text.strip() + \"\\n\"\n",
    "\treturn content\n",
    "\n",
    "def get_author(body: WebElement):\n",
    "\ttry:\n",
    "\t\treturn body.find_element(By.CLASS_NAME, \"autor\").text.strip()\n",
    "\texcept Exception:\n",
    "\t\treturn \"The website does not provide an author\"\n",
    "\n",
    "def get_description(body: WebElement):\n",
    "\treturn \"not found\"\n",
    "\n",
    "extract_data_from_page(\n",
    "\tinput_file=pages_file_name, \n",
    "\toutput_file=content_file_name,\n",
    "\tget_author=get_author,\n",
    "\tget_description=get_description,\n",
    "\tget_content=get_content,\n",
    "\tlimit_of_pages=5,\n",
    "\twait=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "months = {\n",
    "    \"ene\": \"Jan\", \"feb\": \"Feb\", \"mar\": \"Mar\", \"abr\": \"Apr\",\n",
    "    \"may\": \"May\", \"jun\": \"Jun\", \"jul\": \"Jul\", \"ago\": \"Aug\",\n",
    "    \"sept\": \"Sep\", \"oct\": \"Oct\", \"nov\": \"Nov\", \"dic\": \"Dec\"\n",
    "}\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'C')\n",
    "\n",
    "json_pages_info = {\"pages\": []}\n",
    "\n",
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "pages = 10\n",
    "\n",
    "for page in range(0, pages):\n",
    "\n",
    "\turl = f'https://www.google.com/search?q=%22Estallido+social%22+site%3Awww.ex-ante.cl&tbs=cdr:1,cd_min:11/15/2019,cd_max:12/17/2023&start={page * 10}'\n",
    "\n",
    "\tdriver.get(url)\n",
    "\n",
    "\ttime.sleep(2)\n",
    "\n",
    "\tarticles_section = driver.find_element(By.CLASS_NAME, \"dURPMd\")\n",
    "\tarticles = articles_section.find_elements(By.CLASS_NAME, \"MjjYud\")\n",
    "\n",
    "\tfor article in articles:\n",
    "\t\tprint(\"revisando artículo...\")\n",
    "\t\ttry: \n",
    "\t\t\toriginalDate = article.find_element(By.CLASS_NAME, \"YrbPuc\").find_element(By.TAG_NAME, \"span\").text\n",
    "\t\t\tfor es, en in months.items():\n",
    "\t\t\t\tif es in originalDate:\n",
    "\t\t\t\t\t\toriginalDate = originalDate.replace(es, en)\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\tdate_epoch = int(time.mktime(time.strptime(originalDate, \"%d %b %Y\")))\n",
    "\n",
    "\t\t\tif (date_epoch < 1573786800 or date_epoch > 1702782000):\n",
    "\t\t\t\tprint(\"La noticia no corresponde a la fecha solicitada\")\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\ttry:\n",
    "\t\t\t\ttitle = article.find_element(By.TAG_NAME, \"h3\").text\n",
    "\t\t\t\tdescription = article.find_element(By.CLASS_NAME, \"kb0PBd \").find_elements(By.TAG_NAME, \"span\")[1].text\n",
    "\t\t\t\tlink = article.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "\n",
    "\t\t\t\tlink_info = {\n",
    "\t\t\t\t\t\"newscast\" : \"El Mostrador\",\n",
    "\t\t\t\t\t\"title\": title,\n",
    "\t\t\t\t\t\"description\": description,\n",
    "\t\t\t\t\t\"category\": \"The site does not provide a category\",\n",
    "\t\t\t\t\t\"date\": originalDate,\n",
    "\t\t\t\t\t\"image_link\": \"not found initially\",\n",
    "\t\t\t\t\t\"author\": \"not found initially\",\n",
    "\t\t\t\t\t\"link\": link,\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t\tprint(\"información incluida!\")\n",
    "\t\t\t\tjson_pages_info[\"pages\"].append(link_info)\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(f\"Error al extraer información del artículo: {e}\")\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error al procesar el artículo: {e}\")\n",
    "\t\t\tcontinue\n",
    "\n",
    "print(\"Almacenando información en el archivo JSON...\")\n",
    "with open(f\"../archive/temp/el_mostrador_pages.json\", 'w', encoding='utf-8') as file:\n",
    "\tjson.dump(json_pages_info, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "with open(f\"output.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "\tf.write(driver.page_source)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c04755",
   "metadata": {},
   "source": [
    "## Extraction of content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ede08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extracted_pages = {\"pages\": []}\n",
    "extracted_pages_with_content = {\"pages\": []}\n",
    "total_pages = 0\n",
    "pages_succeeded = 0\n",
    "pages_failed = 0\n",
    "error_occurred = False\n",
    "driver = None\n",
    "ad_message = \"Suscríbase aquí a la newsletter de EL PAÍS América y reciba todas las claves informativas de la actualidad de la región.\"\n",
    "limit_of_pages = \"all\"\n",
    "start_page = 10\n",
    "\n",
    "content = \"\"\n",
    "author = \"\"\n",
    "\n",
    "print(\"[INFO] Loading extracted pages from JSON file...\")\n",
    "with open(\"../archive/pages_extracted/ex_ante/ex_ante_pages.json\", 'r', encoding='utf-8') as file:\n",
    "\t\textracted_pages = json.load(file)\n",
    "\t\tprint(f\"[INFO] {len(extracted_pages['pages'])} pages loaded.\")\n",
    "\t\tif limit_of_pages == \"all\":\n",
    "\t\t\tlimit_of_pages = len(extracted_pages[\"pages\"])\n",
    "\n",
    "\n",
    "if start_page >= len(extracted_pages[\"pages\"]):\n",
    "\t\tprint(f\"[ERROR] start_page is out of range. The maximum page index is {len(extracted_pages['pages']) - 1}.\")\n",
    "\t\traise SystemExit\n",
    "\n",
    "def extract_from_DOM():\n",
    "\t\tprint(\"[INFO] Trying to extract content from DOM...\")\n",
    "\t\tcontent = \"\"\n",
    "\t\tauthor = \"\"\n",
    "\n",
    "\t\tcontent_container = driver.find_element(By.CLASS_NAME, \"contenido-noticia\")\n",
    "\t\tparagraph = content_container.find_elements(By.TAG_NAME, \"p\") if content_container else None\n",
    "\t\tcontent = \"\"\n",
    "\t\tfor p in paragraph:\n",
    "\t\t\tp = p.text.strip()\n",
    "\t\t\tif \"También puede leer.\" in p or \"Lea también:\" in p or \"Para seguir leyendo columnas de Ex-Ante, clic aquí.\" in p:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\tcontent += p + \"\\n\"\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\t\tauthor = driver.find_element(By.CLASS_NAME, \"autor\").text.strip()\n",
    "\t\texcept:\n",
    "\t\t\t\tauthor = \"not found\"\n",
    "\n",
    "\t\tprint(\"[INFO] The content has been extracted. Method: DOM\", flush=True)\n",
    "\t\tif len(content) < 100:\n",
    "\t\t\t\tprint(\"[WARNING] The extracted content is too short.\", flush=True)\n",
    "\t\t\t\tprint(f\"[WARNING] Content: {content}\", flush=True)\n",
    "\t\treturn content, author\n",
    "\n",
    "data_extracted = True\n",
    "re = False\n",
    "\n",
    "print(\"[INFO] Starting extraction process...\")\n",
    "for page_index, page in enumerate(extracted_pages[\"pages\"]):\n",
    "\n",
    "\t\tif \"content\" not in page.keys():\n",
    "\t\t\t\tpage[\"content\"] = \"The content has not been extracted yet\"\n",
    "\n",
    "\t\tif page_index < start_page:\n",
    "\t\t\t\tprint(\"[INFO] Skipping page: \", page_index)\n",
    "\t\t\t\tcontinue\n",
    "\t\tif limit_of_pages == total_pages:\n",
    "\t\t\t\tprint(\"[INFO] Limit of pages reached.\")\n",
    "\t\t\t\tbreak\n",
    "\t\tif page[\"content\"] != \"The content has not been extracted yet\":\n",
    "\t\t\t\tprint(f\"[INFO] Page {page_index} already has content. Skipping...\")\n",
    "\t\t\t\textracted_pages_with_content[\"pages\"].append(page)\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\ttotal_pages += 1\n",
    "\n",
    "\t\tprint(f\"\\n[INFO] Checking page: {page_index} | Link: {page['link']}\" )\n",
    "\t\turl = page['link']\n",
    "\t\tfirst = True\n",
    "\n",
    "\t\twhile (re or first):\n",
    "\t\t\tfirst = False\n",
    "\t\t\t\n",
    "\t\t\ttry: \n",
    "\t\t\t\ttime.sleep(1)\n",
    "\n",
    "\t\t\t\tif (not re): \n",
    "\t\t\t\t\toptions = uc.ChromeOptions()\n",
    "\t\t\t\t\toptions.add_argument(\"--no-sandbox\")\n",
    "\t\t\t\t\toptions.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "\t\t\t\t\tdriver = uc.Chrome(options=options)\n",
    "\n",
    "\t\t\t\t\tdriver.get(url)\n",
    "\n",
    "\t\t\t\tre = False\n",
    "\t\t\t\ttime.sleep(random.uniform(6, 12))\n",
    "\n",
    "\t\t\t\ttry: \n",
    "\t\t\t\t\tcontent, author = extract_from_DOM()\n",
    "\t\t\t\t\tif author == \"not found\":\n",
    "\t\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\t\t\tauthor = driver.find_element(By.CLASS_NAME, \"a_md_a\").text.strip()\n",
    "\t\t\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\t\t\t\tauthor = \"not found\"\n",
    "\n",
    "\t\t\t\t\t# Clean up ad message\n",
    "\t\t\t\t\tcontent = content.replace(ad_message, \"\").strip()\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint(f\"[ERROR] A error occurred while extracting content\", flush=True)\n",
    "\t\t\t\t\traise\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(f\"[ERROR] A error occurred while processing the page: {page_index}\", flush=True)\n",
    "\t\t\t\tprint(f\"[ERROR] Site: {url}\", flush=True)\n",
    "\t\t\t\tprint(e, flush=True)\n",
    "\t\t\t\tresponse = input(\"Retry? y/n\")\n",
    "\t\t\t\tif response.lower() == 'y':\n",
    "\t\t\t\t\tprint(\"[INFO] Retry...\")\n",
    "\t\t\t\t\tre = True\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tprint(\"[INFO] Cancelling...\")\n",
    "\t\t\t\t\terror_occurred = True\n",
    "\t\t\t\t\tre = False\n",
    "\t\t\t\n",
    "\t\t\tif (not re):\n",
    "\t\t\t\tdriver.quit()\n",
    "\n",
    "\t\tif error_occurred:\n",
    "\t\t\tcontent = \"A error occurred while extracting content\"\n",
    "\t\t\tauthor = \"A error occurred while extracting content\"\n",
    "\t\t\tpages_failed += 1\n",
    "\t\t\terror_occurred = False\n",
    "\t\telse:\n",
    "\t\t\tpages_succeeded += 1\n",
    "\n",
    "\t\tpage[\"content\"] = content\n",
    "\t\tpage[\"author\"] = author\n",
    "\t\textracted_pages_with_content[\"pages\"].append(page)\n",
    "\n",
    "\t\tprint(\"[INFO] Storing information in a JSON file...\")\n",
    "\t\twith open(f\"../archive/temp/pages_with_content/ex_ante_pages_with_content.json\", 'w', encoding='utf-8') as file:\n",
    "\t\t\tjson.dump(extracted_pages_with_content, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\t\tdriver.quit()\n",
    "\n",
    "\t\ttime.sleep(random.uniform(6, 12))\n",
    "\n",
    "# ----------------- Stats -----------------\n",
    "print(\"\\n\\n\")\n",
    "print(\"----- STATS -----\")\n",
    "\n",
    "try:\n",
    "\tprint(f\"Amount of pages processed: {total_pages}\")\n",
    "\tprint(f\"% Pages succeeded [{pages_succeeded}]: {round(100 * pages_succeeded/total_pages, 2)}\")\n",
    "\tprint(f\"% Pages failed [{pages_failed}]: {round(100 * pages_failed/total_pages, 2)}\")\n",
    "except: \n",
    "\tprint(\"A error occurred while processing the stats\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
