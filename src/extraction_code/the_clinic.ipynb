{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e3f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extraction import extract_articles_from_google\n",
    "from extraction import extract_data_from_page\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_file_name = \"the_clinic_articles.json\"\n",
    "content_file_name = \"the_clinic_articles_with_content.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41067fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_articles_from_google(\n",
    "\twebsite=\"theclinic.cl\",\n",
    "\tnewscast=\"The Clinic\",\n",
    "    keywords=\"Estallido Social\",\n",
    "    output=pages_file_name,\n",
    "    pages=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(body: WebElement):\n",
    "\tcontent = \"\"\n",
    "\tfor element in body.find_element(By.CLASS_NAME, \"the-content\").find_elements(By.TAG_NAME, \"p\"):\n",
    "\t\tif \"Volver al Home\" in element.text or \"También puedes leer\" in element.text:\n",
    "\t\t\tcontinue\n",
    "\t\tcontent += element.text.strip() + \"\\n\"\n",
    "\treturn content\n",
    "\n",
    "def get_author(body: WebElement):\n",
    "\ttry:\n",
    "\t\treturn body.find_element(By.CLASS_NAME, \"autor\").find_element(By.TAG_NAME, \"a\").text.strip()\n",
    "\texcept:\n",
    "\t\treturn \"not found\"\n",
    "\n",
    "def get_description(body: WebElement):\n",
    "\treturn \"not found\"\n",
    "\n",
    "\n",
    "extract_data_from_page(\n",
    "\tinput_file=pages_file_name, \n",
    "\toutput_file=content_file_name,\n",
    "\tget_author=get_author,\n",
    "\tget_description=get_description,\n",
    "\tget_content=get_content,\n",
    " \tlimit_of_pages=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_pages_info = {\"pages\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c0f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import random\n",
    "\n",
    "months = {\n",
    "    \"ene\": \"Jan\", \"feb\": \"Feb\", \"mar\": \"Mar\", \"abr\": \"Apr\",\n",
    "    \"may\": \"May\", \"jun\": \"Jun\", \"jul\": \"Jul\", \"ago\": \"Aug\",\n",
    "    \"sept\": \"Sep\", \"oct\": \"Oct\", \"nov\": \"Nov\", \"dic\": \"Dec\"\n",
    "}\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'C')\n",
    "\n",
    "json_pages_info = {\"pages\": []}\n",
    "\n",
    "pages = 10\n",
    "\n",
    "re = False\n",
    "\n",
    "for page in range(0, pages):\n",
    "\n",
    "\tfirst = True\n",
    "\twhile (re or first):\n",
    "\t\tfirst = False\n",
    "\t\t\n",
    "\t\ttry: \n",
    "\t\t\ttime.sleep(1)\n",
    "\n",
    "\t\t\tif (not re): \n",
    "\t\t\t\toptions = uc.ChromeOptions()\n",
    "\t\t\t\toptions.add_argument(\"--no-sandbox\")\n",
    "\t\t\t\toptions.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "\t\t\t\tdriver = uc.Chrome(options=options)\n",
    "\n",
    "\t\t\t\turl = f'https://www.google.com/search?q=%22Estallido+social%22+site%3Awww.theclinic.cl&tbs=cdr:1,cd_min:11/15/2019,cd_max:12/17/2023&start={page * 10}'\n",
    "\t\t\t\tdriver.get(url)\n",
    "\n",
    "\t\t\tre = False\n",
    "\t\t\ttime.sleep(random.uniform(6, 12))\n",
    "\n",
    "\t\t\tarticles_section = driver.find_element(By.CLASS_NAME, \"dURPMd\")\n",
    "\t\t\tarticles = articles_section.find_elements(By.CLASS_NAME, \"MjjYud\")\n",
    "\n",
    "\t\t\tfor article in articles:\n",
    "\t\t\t\tprint(\"revisando artículo...\")\n",
    "\t\t\t\ttry: \n",
    "\t\t\t\t\toriginalDate = article.find_element(By.CLASS_NAME, \"YrbPuc\").find_element(By.TAG_NAME, \"span\").text\n",
    "\t\t\t\t\tfor es, en in months.items():\n",
    "\t\t\t\t\t\tif es in originalDate:\n",
    "\t\t\t\t\t\t\t\toriginalDate = originalDate.replace(es, en)\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\tdate_epoch = int(time.mktime(time.strptime(originalDate, \"%d %b %Y\")))\n",
    "\n",
    "\t\t\t\t\tif (date_epoch < 1573786800 or date_epoch > 1702782000):\n",
    "\t\t\t\t\t\tprint(\"La noticia no corresponde a la fecha solicitada\")\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\t# check if the article is from El Mostrador\n",
    "\t\t\t\t\tif (not (\"www.theclinic.cl\" in article.text)):\n",
    "\t\t\t\t\t\tprint(\"El artículo no es de The Clinic\")\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\ttitle = article.find_element(By.TAG_NAME, \"h3\").text\n",
    "\t\t\t\t\t\tdescription = article.find_element(By.CLASS_NAME, \"kb0PBd \").find_elements(By.TAG_NAME, \"span\")[1].text\n",
    "\t\t\t\t\t\tlink = article.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "\n",
    "\t\t\t\t\t\tlink_info = {\n",
    "\t\t\t\t\t\t\t\"newscast\" : \"The Clinic\",\n",
    "\t\t\t\t\t\t\t\"title\": title,\n",
    "\t\t\t\t\t\t\t\"description\": description,\n",
    "\t\t\t\t\t\t\t\"category\": \"The site does not provide a category\",\n",
    "\t\t\t\t\t\t\t\"date\": originalDate,\n",
    "\t\t\t\t\t\t\t\"image_link\": \"not found initially\",\n",
    "\t\t\t\t\t\t\t\"author\": \"not found initially\",\n",
    "\t\t\t\t\t\t\t\"link\": link,\n",
    "\t\t\t\t\t\t}\n",
    "\n",
    "\t\t\t\t\t\tprint(\"información incluida!\")\n",
    "\t\t\t\t\t\tjson_pages_info[\"pages\"].append(link_info)\n",
    "\n",
    "\t\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\t\tprint(f\"Error al extraer información del artículo: {e}\")\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint(f\"Error al procesar el artículo: {e}\")\n",
    "\t\t\t\t\tcontinue\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error al procesar el resultado de busqueda. Página: {page}\")\n",
    "\t\t\tprint(f\"Sitio: {url}\")\n",
    "\t\t\tprint(e)\n",
    "\t\t\tresponse = input(\"Reintentar? y/n\")\n",
    "\t\t\tif response.lower() == 'y':\n",
    "\t\t\t\tprint(\"Reintentando.\")\n",
    "\t\t\t\tre = True\n",
    "\t\t\telse: \n",
    "\t\t\t\tprint(\"Cancelando...\")\n",
    "\t\t\t\tre = False\n",
    "\t\t\n",
    "\t\tif (not re):\n",
    "\t\t\tdriver.quit()\n",
    "\n",
    "print(\"Almacenando información en el archivo JSON...\")\n",
    "with open(f\"../archive/temp/the_clinic.json\", 'w', encoding='utf-8') as file:\n",
    "\tjson.dump(json_pages_info, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "# with open(f\"output.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "# \tf.write(driver.page_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a17705",
   "metadata": {},
   "source": [
    "# Content Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_pages = {\"pages\": []}\n",
    "extracted_pages_with_content = {\"pages\": []}\n",
    "last_extracted_pages_with_content = {\"pages\": []}\n",
    "\n",
    "total_pages = 0\n",
    "pages_succeeded = 0\n",
    "pages_failed = 0\n",
    "error_occurred = False\n",
    "driver = None\n",
    "ad_message = \"Suscríbase aquí a la newsletter de EL PAÍS América y reciba todas las claves informativas de la actualidad de la región.\"\n",
    "limit_of_pages = \"all\"\n",
    "start_page = 0\n",
    "\n",
    "content = \"\"\n",
    "author = \"\"\n",
    "\n",
    "test_specific_url = \"\"\n",
    "\n",
    "def recursive_search(element):\n",
    "\t\telement_tag_name = element.tag_name\n",
    "\t\t# get class of a element\n",
    "\t\tif element.get_attribute(\"class\") == \"bloque-tc-dos-recomendados\":\n",
    "\t\t\t\treturn \"\"\n",
    "\t\tif element_tag_name == \"p\" or element_tag_name == \"span\" or element_tag_name == \"h2\" or element_tag_name == \"h3\" or element_tag_name == \"h4\" or element_tag_name == \"a\":\n",
    "\t\t\t\treturn element.text.strip()\n",
    "\t\t\n",
    "\t\tchildren = element.find_elements(By.XPATH, \".//*\")\n",
    "\t\tfor child in children:\n",
    "\t\t\t\tresult = recursive_search(child)\n",
    "\t\t\t\tif result:\n",
    "\t\t\t\t\t\treturn result\n",
    "\t\treturn \"\"\n",
    "\n",
    "print(\"[INFO] Loading extracted pages from JSON file...\")\n",
    "with open(\"../archive/pages_extracted/the_clinic/the_clinic_240725.json\", 'r', encoding='utf-8') as file:\n",
    "\t\textracted_pages = json.load(file)\n",
    "\t\tprint(f\"[INFO] {len(extracted_pages['pages'])} pages loaded.\")\n",
    "\t\tif limit_of_pages == \"all\":\n",
    "\t\t\t\tlimit_of_pages = len(extracted_pages[\"pages\"])\n",
    "\t\t\t\tprint(f\"[INFO] Limit of pages set to {limit_of_pages}\")\n",
    "\n",
    "# with open(\"../archive/temp/pages_with_content/the_clinic_240725_with_content_reference.json\", 'r', encoding='utf-8') as file:\n",
    "# \t\tlast_extracted_pages_with_content = json.load(file)\n",
    "# \t\tprint(f\"[INFO] {len(last_extracted_pages_with_content['pages'])} pages loaded.\")\n",
    "\n",
    "\n",
    "if start_page >= len(extracted_pages[\"pages\"]):\n",
    "\t\tprint(f\"[ERROR] start_page is out of range. The maximum page index is {len(extracted_pages['pages']) - 1}.\")\n",
    "\t\traise SystemExit\n",
    "\n",
    "def extract_from_DOM():\n",
    "\t\tprint(\"[INFO] Trying to extract content from DOM...\")\n",
    "\t\tcontent = \"\"\n",
    "\t\tauthor = \"\"\n",
    "\n",
    "\t\tcontent_container = body.find_element(By.CLASS_NAME, \"the-content\")\n",
    "\t\t# paragraph = content_container.find_elements(By.TAG_NAME, \"p\") if content_container else None\n",
    "\t\tparagraph_elements = content_container.find_elements(By.XPATH, \"./*\")\n",
    "\t\tcontent = \"\"\n",
    "\n",
    "\t\tfor element in paragraph_elements:\n",
    "\t\t\tp = recursive_search(element)\n",
    "\t\t\tif \"Volver al Home\" in p or \"También puedes leer\" in p:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\tcontent += p + \"\\n\"\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\t\tauthor = body.find_element(By.CLASS_NAME, \"autor\").find_element(By.TAG_NAME, \"a\").text.strip()\n",
    "\t\texcept:\n",
    "\t\t\t\tauthor = \"not found\"\n",
    "\n",
    "\t\tprint(\"[INFO] The content has been extracted. Method: DOM\", flush=True)\n",
    "\t\tif len(content) < 100:\n",
    "\t\t\t\tprint(\"[WARNING] The extracted content is too short.\", flush=True)\n",
    "\t\t\t\tprint(f\"[WARNING] Content: {content}\", flush=True)\n",
    "\t\treturn content, author\n",
    "\n",
    "data_extracted = True\n",
    "re = False\n",
    "\n",
    "print(\"[INFO] Starting extraction process...\")\n",
    "for page_index, page in enumerate(extracted_pages[\"pages\"]):\n",
    "\n",
    "\t\tif test_specific_url == \"\":\n",
    "\t\t\tif total_pages >= limit_of_pages:\n",
    "\t\t\t\t\tprint(\"[INFO] Limit of pages reached.\")\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tif \"content\" not in page.keys():\n",
    "\t\t\t\t\tpage[\"content\"] = \"The content has not been extracted yet\"\n",
    "\n",
    "\t\t\tif page_index < start_page:\n",
    "\t\t\t\t\tif page_index < len(last_extracted_pages_with_content[\"pages\"]):\n",
    "\t\t\t\t\t\t\textracted_pages_with_content[\"pages\"].append(last_extracted_pages_with_content[\"pages\"][page_index])\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\textracted_pages_with_content[\"pages\"].append(page)\n",
    "\t\t\t\t\tprint(\"[INFO] Skipping page: \", page_index)\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\tif page[\"content\"] != \"The content has not been extracted yet\":\n",
    "\t\t\t\t\tprint(f\"[INFO] Page {page_index} already has content. Skipping...\")\n",
    "\t\t\t\t\textracted_pages_with_content[\"pages\"].append(page)\n",
    "\t\t\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\tprint(\"[INFO] Processing specific page: \", test_specific_url)\n",
    "\t\t\tfor page_aux in extracted_pages[\"pages\"]:\n",
    "\t\t\t\tif page_aux[\"link\"] == test_specific_url:\n",
    "\t\t\t\t\tpage = page_aux\n",
    "\t\t\t\t\ttest_specific_url = \"\"\n",
    "\t\t\t\t\ttotal_pages = 99999\n",
    "\t\t\t\t\tprint(\"[INFO] The specific page found!\")\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\ttotal_pages += 1\n",
    "\n",
    "\t\tprint(f\"\\n[INFO] Checking page: {page_index} | Link: {page['link']}\" )\n",
    "\t\turl = page['link']\n",
    "\t\tfirst = True\n",
    "\n",
    "\t\twhile (re or first):\n",
    "\t\t\tfirst = False\n",
    "\t\t\t\n",
    "\t\t\ttry: \n",
    "\t\t\t\ttime.sleep(1)\n",
    "\n",
    "\t\t\t\tif (not re): \n",
    "\t\t\t\t\toptions = uc.ChromeOptions()\n",
    "\t\t\t\t\toptions.add_argument(\"--no-sandbox\")\n",
    "\t\t\t\t\toptions.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "\t\t\t\t\tdriver = uc.Chrome(options=options)\n",
    "\t\t\t\t\tprint(\"[INFO] Chrome driver initialized.\")\n",
    "\t\t\t\t\tdriver.get(url)\n",
    "\t\t\t\t\tprint(\"[INFO] Page loaded.\")\n",
    "\n",
    "\t\t\t\tre = False\n",
    "\t\t\t\ttime.sleep(random.uniform(6, 12))\n",
    "\t\t\t\tbody = driver.find_element(By.TAG_NAME, 'body')\n",
    "\n",
    "\t\t\t\ttry: \n",
    "\t\t\t\t\tcontent, author = extract_from_DOM()\n",
    "\n",
    "\t\t\t\t\t# Clean up ad message\n",
    "\t\t\t\t\tcontent = content.replace(ad_message, \"\").strip()\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint(f\"[ERROR] A error occurred while extracting content\", flush=True)\n",
    "\t\t\t\t\traise\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(f\"[ERROR] A error occurred while processing the page: {page_index}\", flush=True)\n",
    "\t\t\t\tprint(f\"[ERROR] Site: {url}\", flush=True)\n",
    "\t\t\t\tprint(e, flush=True)\n",
    "\t\t\t\tresponse = input(\"Retry? y/n\")\n",
    "\t\t\t\tif response.lower() == 'y':\n",
    "\t\t\t\t\tprint(\"[INFO] Retry...\")\n",
    "\t\t\t\t\tre = True\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tresponse = input(\"Description? Press enter to not add a description\")\n",
    "\t\t\t\t\tif not response:\n",
    "\t\t\t\t\t\t\tresponse = \"No description provided\"\n",
    "\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\tprint(f\"[INFO] The user add a description: {response}\")\n",
    "\t\t\t\t\tprint(\"[INFO] Cancelling...\")\n",
    "\t\t\t\t\terror_occurred = True\n",
    "\t\t\t\t\tpage[\"Observation\"] = \"A error occurred while extracting content. The user cancelled the operation. Description: \" + response\n",
    "\t\t\t\t\tre = False\n",
    "\t\t\t\n",
    "\t\t\tif (not re):\n",
    "\t\t\t\tdriver.quit()\n",
    "\n",
    "\t\tif error_occurred:\n",
    "\t\t\tcontent = \"A error occurred while extracting content\"\n",
    "\t\t\tauthor = \"A error occurred while extracting content\"\n",
    "\t\t\tpages_failed += 1\n",
    "\t\t\terror_occurred = False\n",
    "\t\telse:\n",
    "\t\t\tpages_succeeded += 1\n",
    "\n",
    "\t\tpage[\"content\"] = content\n",
    "\t\tpage[\"author\"] = author\n",
    "\t\textracted_pages_with_content[\"pages\"].append(page)\n",
    "\n",
    "\t\tprint(\"[INFO] Storing information in a JSON file...\")\n",
    "\t\twith open(f\"../archive/temp/pages_with_content/the_clinic_240725_with_content.json\", 'w', encoding='utf-8') as file:\n",
    "\t\t\tjson.dump(extracted_pages_with_content, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\t\tdriver.quit()\n",
    "\n",
    "\t\ttime.sleep(random.uniform(6, 12))\n",
    "\n",
    "# ----------------- Stats -----------------\n",
    "print(\"\\n\\n\")\n",
    "print(\"----- STATS -----\")\n",
    "\n",
    "try:\n",
    "\tprint(f\"Amount of pages processed: {total_pages}\")\n",
    "\tprint(f\"% Pages succeeded [{pages_succeeded}]: {round(100 * pages_succeeded/total_pages, 2)}\")\n",
    "\tprint(f\"% Pages failed [{pages_failed}]: {round(100 * pages_failed/total_pages, 2)}\")\n",
    "except: \n",
    "\tprint(\"A error occurred while processing the stats\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
